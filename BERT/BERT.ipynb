{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install datasets transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-10T18:36:41.127238Z","iopub.execute_input":"2024-08-10T18:36:41.127941Z","iopub.status.idle":"2024-08-10T18:36:54.350543Z","shell.execute_reply.started":"2024-08-10T18:36:41.127905Z","shell.execute_reply":"2024-08-10T18:36:54.349636Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:22.726494Z","iopub.execute_input":"2024-08-10T18:37:22.727366Z","iopub.status.idle":"2024-08-10T18:37:23.007408Z","shell.execute_reply.started":"2024-08-10T18:37:22.727330Z","shell.execute_reply":"2024-08-10T18:37:23.006558Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8ecbcc5261841cdaf893eb21ae5146d"}},"metadata":{}}]},{"cell_type":"code","source":"!apt install git-lfs","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:25.099172Z","iopub.execute_input":"2024-08-10T18:37:25.100011Z","iopub.status.idle":"2024-08-10T18:37:28.147523Z","shell.execute_reply.started":"2024-08-10T18:37:25.099976Z","shell.execute_reply":"2024-08-10T18:37:28.146417Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ngit-lfs is already the newest version (2.9.2-1).\n0 upgraded, 0 newly installed, 0 to remove and 80 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\n\nprint(transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:30.566115Z","iopub.execute_input":"2024-08-10T18:37:30.566897Z","iopub.status.idle":"2024-08-10T18:37:34.014838Z","shell.execute_reply.started":"2024-08-10T18:37:30.566862Z","shell.execute_reply":"2024-08-10T18:37:34.013910Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"4.42.3\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers.utils import send_example_telemetry\n\nsend_example_telemetry(\"question_answering_notebook\", framework=\"pytorch\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:36.694194Z","iopub.execute_input":"2024-08-10T18:37:36.694891Z","iopub.status.idle":"2024-08-10T18:37:36.702402Z","shell.execute_reply.started":"2024-08-10T18:37:36.694858Z","shell.execute_reply":"2024-08-10T18:37:36.701652Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:38.882213Z","iopub.execute_input":"2024-08-10T18:37:38.882919Z","iopub.status.idle":"2024-08-10T18:37:40.056130Z","shell.execute_reply.started":"2024-08-10T18:37:38.882887Z","shell.execute_reply":"2024-08-10T18:37:40.055270Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the PIQA dataset\ndataset = load_dataset(\"piqa\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:41.916330Z","iopub.execute_input":"2024-08-10T18:37:41.917380Z","iopub.status.idle":"2024-08-10T18:37:49.245442Z","shell.execute_reply.started":"2024-08-10T18:37:41.917343Z","shell.execute_reply":"2024-08-10T18:37:49.244520Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88bb4de1eea643d8ac706241790cfeca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/8.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95518bd4f9bf41e090787f7b493a8ab1"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for piqa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/piqa.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ea1bc6b334a4768873987b14f8d7d54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/815k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0ef81727584b8ca2f4a856fd1721dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa060f4a5bf048b0afe927dd701bb4e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3084 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd4c095895304f6697d769686efce4e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1838 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e6088b9222c4e49b1c70e0a940ae1bd"}},"metadata":{}}]},{"cell_type":"code","source":"# Display the keys of the dataset\nprint(dataset)\n\n# Display the first example from the training set\nfirst_example = dataset['train'][0]\nprint(first_example)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:53.131170Z","iopub.execute_input":"2024-08-10T18:37:53.131558Z","iopub.status.idle":"2024-08-10T18:37:53.138908Z","shell.execute_reply.started":"2024-08-10T18:37:53.131527Z","shell.execute_reply":"2024-08-10T18:37:53.137755Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['goal', 'sol1', 'sol2', 'label'],\n        num_rows: 16113\n    })\n    test: Dataset({\n        features: ['goal', 'sol1', 'sol2', 'label'],\n        num_rows: 3084\n    })\n    validation: Dataset({\n        features: ['goal', 'sol1', 'sol2', 'label'],\n        num_rows: 1838\n    })\n})\n{'goal': \"When boiling butter, when it's ready, you can\", 'sol1': 'Pour it onto a plate', 'sol2': 'Pour it into a jar', 'label': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = dataset['train']\nval_dataset = dataset['validation']\ntest_dataset = dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:56.581379Z","iopub.execute_input":"2024-08-10T18:37:56.582005Z","iopub.status.idle":"2024-08-10T18:37:56.586178Z","shell.execute_reply.started":"2024-08-10T18:37:56.581971Z","shell.execute_reply":"2024-08-10T18:37:56.585283Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(train_dataset[0])  # This will show you the structure of a sample in the train split\nprint(val_dataset[0])\nprint(test_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:37:59.012910Z","iopub.execute_input":"2024-08-10T18:37:59.013767Z","iopub.status.idle":"2024-08-10T18:37:59.020462Z","shell.execute_reply.started":"2024-08-10T18:37:59.013724Z","shell.execute_reply":"2024-08-10T18:37:59.019450Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{'goal': \"When boiling butter, when it's ready, you can\", 'sol1': 'Pour it onto a plate', 'sol2': 'Pour it into a jar', 'label': 1}\n{'goal': \"How do I ready a guinea pig cage for it's new occupants?\", 'sol1': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped paper strips, you will also need to supply it with a water bottle and a food dish.', 'sol2': 'Provide the guinea pig with a cage full of a few inches of bedding made of ripped jeans material, you will also need to supply it with a water bottle and a food dish.', 'label': 0}\n{'goal': 'how do you puncture a vein?', 'sol1': 'hit it at the wrong angle and make it bleed.', 'sol2': 'pop it.', 'label': -1}\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:38:00.735173Z","iopub.execute_input":"2024-08-10T18:38:00.736062Z","iopub.status.idle":"2024-08-10T18:38:02.734380Z","shell.execute_reply.started":"2024-08-10T18:38:00.736028Z","shell.execute_reply":"2024-08-10T18:38:02.733619Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eee33b431fd944e5b5bd32d291855c72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f475a4f6a0ac44c58c3a6bc6345901cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f5c70a9fc0466b96e72873abc79693"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36a0ee2e09aa4e9ebcb125616e76a8e1"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel_checkpoint = \"bert-large-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:40:38.788219Z","iopub.execute_input":"2024-08-10T19:40:38.788603Z","iopub.status.idle":"2024-08-10T19:40:39.669447Z","shell.execute_reply.started":"2024-08-10T19:40:38.788560Z","shell.execute_reply":"2024-08-10T19:40:39.668709Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = dataset['train']\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:38:10.624037Z","iopub.execute_input":"2024-08-10T18:38:10.624932Z","iopub.status.idle":"2024-08-10T18:38:10.628858Z","shell.execute_reply.started":"2024-08-10T18:38:10.624896Z","shell.execute_reply":"2024-08-10T18:38:10.627982Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(train_dataset[1])","metadata":{"execution":{"iopub.status.busy":"2024-08-10T18:38:12.174534Z","iopub.execute_input":"2024-08-10T18:38:12.175227Z","iopub.status.idle":"2024-08-10T18:38:12.180953Z","shell.execute_reply.started":"2024-08-10T18:38:12.175196Z","shell.execute_reply":"2024-08-10T18:38:12.179837Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"{'goal': 'To permanently attach metal legs to a chair, you can', 'sol1': 'Weld the metal together to get it to stay firmly in place', 'sol2': 'Nail the metal together to get it to stay firmly in place', 'label': 0}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(labels))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T14:50:22.499481Z","iopub.execute_input":"2024-08-10T14:50:22.499829Z","iopub.status.idle":"2024-08-10T14:50:22.504639Z","shell.execute_reply.started":"2024-08-10T14:50:22.499802Z","shell.execute_reply":"2024-08-10T14:50:22.503714Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"32226\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass PIQADataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Assuming you're working with the training dataset\ntrain_dataset = dataset['train']  # Accessing the 'train' split\n\n# Encode the inputs for both solutions\nencodings = tokenizer(\n    [f\"{item['goal']} [SEP] {item['sol1'] if item['label'] == 1 else item['sol2']}\" \n     for item in train_dataset],\n    truncation=True, padding=True, return_tensors='pt'\n)\n\n# Create the labels (1 for sol1, 0 for sol2)\nlabels = [item['label'] for item in train_dataset]\n\n# Create the dataset\npiqa_dataset = PIQADataset(encodings, labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:41:07.703802Z","iopub.execute_input":"2024-08-10T19:41:07.704639Z","iopub.status.idle":"2024-08-10T19:41:20.055017Z","shell.execute_reply.started":"2024-08-10T19:41:07.704604Z","shell.execute_reply":"2024-08-10T19:41:20.054064Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(encodings)\n\n# Get the first sequence of input IDs\ninput_ids = encodings['input_ids'][0]\n\n# Decode the input IDs back to text\ndecoded_text = tokenizer.decode(input_ids)\n\nprint(decoded_text)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:41:50.413848Z","iopub.execute_input":"2024-08-10T19:41:50.414736Z","iopub.status.idle":"2024-08-10T19:41:50.424181Z","shell.execute_reply.started":"2024-08-10T19:41:50.414699Z","shell.execute_reply":"2024-08-10T19:41:50.423212Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[  101,  2043, 16018,  ...,     0,     0,     0],\n        [  101,  2000,  8642,  ...,     0,     0,     0],\n        [  101,  2129,  2079,  ...,     0,     0,     0],\n        ...,\n        [  101,  2000,  7744,  ...,     0,     0,     0],\n        [  101,  2191, 14380,  ...,     0,     0,     0],\n        [  101,  2129,  2079,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        ...,\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])}\n[CLS] when boiling butter, when it's ready, you can [SEP] pour it onto a plate [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","output_type":"stream"}]},{"cell_type":"code","source":"piqa_dataset[1]","metadata":{"execution":{"iopub.status.busy":"2024-08-10T14:58:10.527879Z","iopub.execute_input":"2024-08-10T14:58:10.528254Z","iopub.status.idle":"2024-08-10T14:58:10.539748Z","shell.execute_reply.started":"2024-08-10T14:58:10.528226Z","shell.execute_reply":"2024-08-10T14:58:10.538844Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([  101,  2000,  8642, 22476,  3384,  3456,  2000,  1037,  3242,  1010,\n          2017,  2064,   102, 13774,  1996,  3384,  2362,  2000,  2131,  2009,\n          2000,  2994,  7933,  1999,  2173,   102,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'labels': 0}"},"metadata":{}}]},{"cell_type":"code","source":"# Access the validation split\nval_dataset = dataset['validation']\n\n# Encode the inputs for the validation set\nval_encodings = tokenizer(\n    [f\"{item['goal']} [SEP] {item['sol1'] if item['label'] == 1 else item['sol2']}\" \n     for item in val_dataset],\n    truncation=True, padding=True, return_tensors='pt'\n)\n\n# Extract the correct labels from the validation dataset\nval_labels = [item['label'] for item in val_dataset]\n\n# Create the validation dataset\nval_piqadataset = PIQADataset(val_encodings, val_labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:41:58.259983Z","iopub.execute_input":"2024-08-10T19:41:58.260345Z","iopub.status.idle":"2024-08-10T19:41:59.092304Z","shell.execute_reply.started":"2024-08-10T19:41:58.260317Z","shell.execute_reply":"2024-08-10T19:41:59.091452Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(val_piqadataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:42:06.039133Z","iopub.execute_input":"2024-08-10T19:42:06.039496Z","iopub.status.idle":"2024-08-10T19:42:06.051031Z","shell.execute_reply.started":"2024-08-10T19:42:06.039468Z","shell.execute_reply":"2024-08-10T19:42:06.050147Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([  101,  2129,  2079,  1045,  3201,  1037,  7102, 10369,  7980,  2005,\n         2009,  1005,  1055,  2047, 18837,  1029,   102,  3073,  1996,  7102,\n        10369,  2007,  1037,  7980,  2440,  1997,  1037,  2261,  5282,  1997,\n         2793,  4667,  2081,  1997,  9157,  6312,  3430,  1010,  2017,  2097,\n         2036,  2342,  2000,  4425,  2009,  2007,  1037,  2300,  5835,  1998,\n         1037,  2833,  9841,  1012,   102,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': 0}\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Create the DataLoader\nbatch_size = 16  # You can adjust this based on your GPU's memory capacity\ntrain_dataloader = DataLoader(piqa_dataset, batch_size=batch_size, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:42:09.820137Z","iopub.execute_input":"2024-08-10T19:42:09.820775Z","iopub.status.idle":"2024-08-10T19:42:09.825606Z","shell.execute_reply.started":"2024-08-10T19:42:09.820742Z","shell.execute_reply":"2024-08-10T19:42:09.824634Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\n# Load the pre-trained model\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:42:16.789794Z","iopub.execute_input":"2024-08-10T19:42:16.790436Z","iopub.status.idle":"2024-08-10T19:42:17.608108Z","shell.execute_reply.started":"2024-08-10T19:42:16.790405Z","shell.execute_reply":"2024-08-10T19:42:17.607363Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",\n    evaluation_strategy=\"epoch\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='./logs',            # Directory for storing logs\n    report_to=\"none\",                 # Disable W&B integration\n    fp16=True,\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:42:20.714826Z","iopub.execute_input":"2024-08-10T19:42:20.715184Z","iopub.status.idle":"2024-08-10T19:42:20.747620Z","shell.execute_reply.started":"2024-08-10T19:42:20.715154Z","shell.execute_reply":"2024-08-10T19:42:20.746748Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=piqa_dataset,        # Your training dataset\n    eval_dataset=val_piqadataset,      # Your validation dataset\n    tokenizer=tokenizer\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:42:24.102094Z","iopub.execute_input":"2024-08-10T19:42:24.102911Z","iopub.status.idle":"2024-08-10T19:42:24.459991Z","shell.execute_reply.started":"2024-08-10T19:42:24.102873Z","shell.execute_reply":"2024-08-10T19:42:24.459193Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:42:26.882740Z","iopub.execute_input":"2024-08-10T19:42:26.883557Z","iopub.status.idle":"2024-08-10T19:42:26.888360Z","shell.execute_reply.started":"2024-08-10T19:42:26.883515Z","shell.execute_reply":"2024-08-10T19:42:26.887318Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:42:30.091089Z","iopub.execute_input":"2024-08-10T19:42:30.091456Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='212' max='6045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 212/6045 04:49 < 2:14:02, 0.73 it/s, Epoch 0.10/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\nmodel = model.to(torch.device(\"cpu\"))","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:09:06.452683Z","iopub.execute_input":"2024-08-10T19:09:06.453042Z","iopub.status.idle":"2024-08-10T19:09:06.728349Z","shell.execute_reply.started":"2024-08-10T19:09:06.453014Z","shell.execute_reply":"2024-08-10T19:09:06.727449Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:09:10.139244Z","iopub.execute_input":"2024-08-10T19:09:10.140092Z","iopub.status.idle":"2024-08-10T19:09:10.147258Z","shell.execute_reply.started":"2024-08-10T19:09:10.140048Z","shell.execute_reply":"2024-08-10T19:09:10.146323Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm  # for progress bar\n\ndevice = next(model.parameters()).device\nprint(f\"Model is on device: {device}\")\n\nmodel.eval()\npredictions = []\n\n# Use tqdm for progress bar\nwith torch.no_grad():\n    for i in tqdm(range(0, len(val_piqadataset), batch_size), desc=\"Processing batches\"):\n        # Ensure we don't go out of bounds\n        batch_end = min(i + batch_size, len(val_piqadataset))\n        batch = {k: v[i:batch_end].to(device) for k, v in val_encodings.items()}\n        outputs = model(**batch)\n        predictions.extend(outputs.logits.argmax(dim=-1).cpu().tolist())\n\n# Process predictions\nfinal_predictions = predictions  # For validation set, we don't need to pair the predictions\n\n# Compare with true labels\ntrue_labels = val_labels  # Using val_labels from the image\ncorrect = sum(p == l for p, l in zip(final_predictions, true_labels))\naccuracy = correct / len(true_labels)\nprint(f\"Validation Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:09:11.882606Z","iopub.execute_input":"2024-08-10T19:09:11.883432Z","iopub.status.idle":"2024-08-10T19:13:43.548092Z","shell.execute_reply.started":"2024-08-10T19:09:11.883390Z","shell.execute_reply":"2024-08-10T19:13:43.547151Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Model is on device: cpu\n","output_type":"stream"},{"name":"stderr","text":"Processing batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:31<00:00,  2.36s/it]","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.5060\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(5):  # Look at the first 5 examples\n    goal = val_dataset['goal'][i]\n    sol1 = val_dataset['sol1'][i]\n    sol2 = val_dataset['sol2'][i]\n    true_label = val_labels[i]  # Using val_labels as defined in the image\n    predicted_label = final_predictions[i]\n    \n    print(f\"Goal: {goal}\")\n    print(f\"Solution 1: {sol1}\")\n    print(f\"Solution 2: {sol2}\")\n    print(f\"True label: {true_label}\")\n    print(f\"Predicted label: {predicted_label}\")\n    print(f\"Correct: {true_label == predicted_label}\")\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:23:49.048136Z","iopub.execute_input":"2024-08-10T19:23:49.049113Z","iopub.status.idle":"2024-08-10T19:23:49.095278Z","shell.execute_reply.started":"2024-08-10T19:23:49.049068Z","shell.execute_reply":"2024-08-10T19:23:49.094295Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Goal: How do I ready a guinea pig cage for it's new occupants?\nSolution 1: Provide the guinea pig with a cage full of a few inches of bedding made of ripped paper strips, you will also need to supply it with a water bottle and a food dish.\nSolution 2: Provide the guinea pig with a cage full of a few inches of bedding made of ripped jeans material, you will also need to supply it with a water bottle and a food dish.\nTrue label: 0\nPredicted label: 1\nCorrect: False\n\n\nGoal: dresser\nSolution 1: replace drawer with bobby pin \nSolution 2: finish, woodgrain with  bobby pin \nTrue label: 1\nPredicted label: 1\nCorrect: True\n\n\nGoal: To fight Ivan Drago in Rocky for sega master system.\nSolution 1: Drago isn't in this game because it was released before Rocky IV.\nSolution 2: You have to defeat Apollo Creed and Clubber Lang first.\nTrue label: 1\nPredicted label: 1\nCorrect: True\n\n\nGoal: Make outdoor pillow.\nSolution 1: Blow into tin can and tie with rubber band.\nSolution 2: Blow into trash bag and tie with rubber band.\nTrue label: 1\nPredicted label: 1\nCorrect: True\n\n\nGoal: ice box\nSolution 1: will turn into a cooler if you add water to it\nSolution 2: will turn into a cooler if you add soda to it\nTrue label: 0\nPredicted label: 1\nCorrect: False\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize counters\ncorrect_count = 0\nwrong_count = 0\n\n# Iterate through all examples in the validation dataset\nfor i in range(len(val_dataset)):\n    true_label = val_labels[i]\n    predicted_label = final_predictions[i]\n    \n    if true_label == predicted_label:\n        correct_count += 1\n    else:\n        wrong_count += 1\n    \n    # Optional: Print details for the first 5 examples\n    if i < 5:\n        goal = val_dataset['goal'][i]\n        sol1 = val_dataset['sol1'][i]\n        sol2 = val_dataset['sol2'][i]\n        \n        print(f\"Example {i+1}:\")\n        print(f\"Goal: {goal}\")\n        print(f\"Solution 1: {sol1}\")\n        print(f\"Solution 2: {sol2}\")\n        print(f\"True label: {true_label}\")\n        print(f\"Predicted label: {predicted_label}\")\n        print(f\"Correct: {true_label == predicted_label}\")\n        print(\"\\n\")\n\n# Calculate accuracy\ntotal_examples = len(val_dataset)\naccuracy = correct_count / total_examples\n\n# Print summary\nprint(f\"Total examples: {total_examples}\")\nprint(f\"Correct predictions: {correct_count}\")\nprint(f\"Wrong predictions: {wrong_count}\")\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:29:21.193051Z","iopub.execute_input":"2024-08-10T19:29:21.193547Z","iopub.status.idle":"2024-08-10T19:29:21.249871Z","shell.execute_reply.started":"2024-08-10T19:29:21.193510Z","shell.execute_reply":"2024-08-10T19:29:21.248875Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Example 1:\nGoal: How do I ready a guinea pig cage for it's new occupants?\nSolution 1: Provide the guinea pig with a cage full of a few inches of bedding made of ripped paper strips, you will also need to supply it with a water bottle and a food dish.\nSolution 2: Provide the guinea pig with a cage full of a few inches of bedding made of ripped jeans material, you will also need to supply it with a water bottle and a food dish.\nTrue label: 0\nPredicted label: 1\nCorrect: False\n\n\nExample 2:\nGoal: dresser\nSolution 1: replace drawer with bobby pin \nSolution 2: finish, woodgrain with  bobby pin \nTrue label: 1\nPredicted label: 1\nCorrect: True\n\n\nExample 3:\nGoal: To fight Ivan Drago in Rocky for sega master system.\nSolution 1: Drago isn't in this game because it was released before Rocky IV.\nSolution 2: You have to defeat Apollo Creed and Clubber Lang first.\nTrue label: 1\nPredicted label: 1\nCorrect: True\n\n\nExample 4:\nGoal: Make outdoor pillow.\nSolution 1: Blow into tin can and tie with rubber band.\nSolution 2: Blow into trash bag and tie with rubber band.\nTrue label: 1\nPredicted label: 1\nCorrect: True\n\n\nExample 5:\nGoal: ice box\nSolution 1: will turn into a cooler if you add water to it\nSolution 2: will turn into a cooler if you add soda to it\nTrue label: 0\nPredicted label: 1\nCorrect: False\n\n\nTotal examples: 1838\nCorrect predictions: 930\nWrong predictions: 908\nAccuracy: 0.5060\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport numpy as np\n\ndef calculate_metrics(true_labels, predictions):\n    # Accuracy\n    accuracy = accuracy_score(true_labels, predictions)\n    \n    # Precision, Recall, and F1 Score\n    precision = precision_score(true_labels, predictions, average='binary')\n    recall = recall_score(true_labels, predictions, average='binary')\n    f1 = f1_score(true_labels, predictions, average='binary')\n    \n    # Confusion Matrix\n    tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()\n    \n    # Specificity (True Negative Rate)\n    specificity = tn / (tn + fp)\n    \n    # Matthews Correlation Coefficient (MCC)\n    mcc_numerator = (tp * tn) - (fp * fn)\n    mcc_denominator = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n    mcc = mcc_numerator / mcc_denominator if mcc_denominator != 0 else 0\n    \n    return {\n        \"Accuracy\": accuracy,\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1 Score\": f1,\n        \"Specificity\": specificity,\n        \"MCC\": mcc,\n        \"True Positives\": tp,\n        \"True Negatives\": tn,\n        \"False Positives\": fp,\n        \"False Negatives\": fn\n    }\n\n# After making predictions\nmetrics = calculate_metrics(val_labels, predictions)\n\n# Print the results\nfor metric, value in metrics.items():\n    print(f\"{metric}: {value:.4f}\")\n\n# Calculate class distribution\nclass_distribution = np.bincount(val_labels) / len(val_labels)\nprint(\"\\nClass Distribution:\")\nfor i, proportion in enumerate(class_distribution):\n    print(f\"Class {i}: {proportion:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T19:33:11.907965Z","iopub.execute_input":"2024-08-10T19:33:11.908585Z","iopub.status.idle":"2024-08-10T19:33:11.942791Z","shell.execute_reply.started":"2024-08-10T19:33:11.908538Z","shell.execute_reply":"2024-08-10T19:33:11.941909Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Accuracy: 0.5060\nPrecision: 0.5056\nRecall: 0.9784\nF1 Score: 0.6667\nSpecificity: 0.0242\nMCC: 0.0088\nTrue Positives: 908.0000\nTrue Negatives: 22.0000\nFalse Positives: 888.0000\nFalse Negatives: 20.0000\n\nClass Distribution:\nClass 0: 49.51%\nClass 1: 50.49%\n","output_type":"stream"}]}]}